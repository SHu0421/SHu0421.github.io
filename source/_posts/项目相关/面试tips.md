---
title: Review Tips
tags: review tips
categories:
  - 项目相关
hide: true
date: 2022-02-23 16:00:36
---


实习的时候应该怎么做：
写实习日记(internship log),记录你每天在工作中做了什么、遇到哪些困难、你是如何解决的;还可以写参加了哪些会议，你在会议上跟着大boss学到了什么(行业的观念，企业发展方向);还有自己悟出来的道理，比如做行业research时，从龙头公司入手而不是小虾米公司入手，这样更有效率。

各个案例支持各种结构化面试的答案，比如你如何克服困难。你可以描述实习中你面对大量数据，不会用excel软件整理数据，是如何自学“从入门到精通”的。于是乎简单的学用办公软件的打杂，也变得高端起来。

面试前好好想想你做过什么、写下来。最好回想一下这些事情，带你的师父教给你了什么?你犯了错误是如何改进的?往往你“犯错-被骂-修改”的这个过程，就是你迅速成长的过程。

有一种可能，就是实习真的啥也没做，在办公室呆了两个月!可是真正求职的时候，这两个月的办公室经验也是可以派得上用场的!辣么，如何把你什么都没干的实习，说得收获很大一样呢?
你可以结合自己的性格，以及在办公室/行业内所学所见，从侧面推荐自己。比如，你做了销售实习，你跟着你的师父去拜访客户，其实也不是你的事情，其实你们根本就吃了闭门羹，啥也没推销出去。可是这个时候，你可以说，你的实习，磨练了你的耐心和耐性、善于沟通、你知道销售工作的礼仪、你勇于尝试去啃难啃的客户和业务。

就是在一项简单的工作中也要有自己的想法和工作的处理方式，或许在整理资料这样的小事中你也有自己的经验，但是没有提炼成方法论。

总结：
1. 思考小事后面学到的方法，逻辑，展现自己的学习能力和潜力；提炼一套方法论
2. 将每件小事写出自己学到了什么；将每件做对的事写出自己的之后如何经一部优化；自己做错的事，下次如何避免改进，进步；遇到困难如何解决
3. 自学linux, 在pytorch官网上进行留言， 在stackoverflow上寻找答案；rpc自学，自学231n；了解了岗位和业务需求，从需求出发
4. 项目优缺点

项目如何包装：


遇到的最大挑战或者困难，令人印象深刻的项目或者工作经历
建议围绕“背景—我的定位—主要价值—当时挑战和我的解法”的框架展开，

目标检测任务：
困难：小目标，目标不均衡，漏检问题和精度较低
最开始学习和了解目标检测的时候，就要完成这个红绿灯交通标志模型的训练。为了完成这样一个任务，我需要快速上手使用公司内部的算法框架训练一个初步模型，同时通过阅读论文和源码了解目标检测模型训练的一些细节
在这个过程中因为最初上手公司算法框架和学习目标检测的原因，我也遇到了一些困难，比如最开始的模型训练精度非常差，于是我从数据的输入格式进行检验，从验证输入，到调试查看内部的输入输出是否正常，查找错误的原因，最后发现，因为算法框架内部存在一个错误，内部是硬编码的格式输入，使得传入的参数失效，因此输出结果错误；之后了解到主要还是由于公司并没有将数据处理这块代码进行统一规范化，导致不同人维护一个不同的代码repo，我从仓库里面拷贝的版本是已经过时的，因此在训练会出现这样一个错误。
除此之外，导致模型精度差的原因主要是由于数据中小目标和数据量差距大，有的类别数量本身就非常少，因此拉低整体训练精度，要解决这个问题，我主要是在模型训练方法进行了改进，我了解到多尺度的输入，以及FPN可以很好解决小目标的问题，focal loss可以解决样本不均衡的问题，因此在训练时候选择了多尺度输入方式，带有FPN网络和focal loss的损失函数来解决这些问题。之后精度上升到一个比较满意的阈值，但是还不够好。最后就是在一些参数的设定上进行微调，找到一个最佳的训练参数。这个我主要是通过先抓住影响精度几个重要参数值，然后在这几个参数上进行尝试调整，使用表格记录+控制变量方式搜索。最后达到一个较为满意的结果。但是我觉得在参数搜索这一块我还可以尝试一些自动化搜索的方式进行进一步优化。



个人研究方向的挑战：
样本重要性算法部分的设计：1）如何确定样本的动态变化重要性， 设计了一种基于历史值+异步更新的方式计算样本重要性； 2）缓存的设计主要不是我做的，但是主要的思路是小根堆，同时需要周期更新这个堆，因此样本重要性变化，可能会导致建立的堆无效，使用一种COW的思想，在重建堆的时候还是使用之前的重要性来置换，之后建好了再替换；cache size是一个需要在实验中验证的参数

将重要性采样算法引入IO为瓶颈的场景本身就是一个挑战，这主要是因为目前没有相关在重要性采样结合系统架构的研究工作，现在的算法主要还是关注计算减少量上减少。第二个就是样本的重要性本身就是动态变化的，如果要减少IO就只能尽可能少将数据取到内存进行计算，那么如何更新样本的重要性。这个问题第一个初步解决方案就是使用历史的重要性，就是将之前的重要性延迟更新，这样话的可以提前根据样本的重要性确定样本取不取，但是这种方式也是有局限的，也并没有解决本质问题，而且可能引入新的问题就是历史值使用多久，以及历史值的偏差对精度影响。因此我在此基础上进行改进，使用了一个在存储端计算的思想，就是利用在PFS中，利用近存储端的计算资源进行计算，保障了重要性实时性，同时为IO时间的减少提供了机会。当然这种方法，也会引入存储端模型同步和重要性同步的通信时间，但是通过理论实验数据证明，多数情况下这个时间比重复数据的传输时间小，因此是可以接受的。除此之外，为了解决针对IO的重要性算法适应范围窄的问题，我在此基础上设计了一个自适应选择算法框架，就是将现有的算法融合进来，通过profile确定瓶颈，然后选择对应最佳采样策略，使得算法使用更广。

难点：进行缓存设计的时候，如何让多进程访问缓存，以及在分布式场景中如何设计缓存
使用rpc进行存储和计算端进程之间的通信



毕业设计的挑战：
如何判断哪些参数是冗余的，因此可以删除，哪些是重要的，需要被保留。
保留精度敬克能不受影响，最大化压缩率
training，pruning，fine-tuning三段式
这个问题我主要是通过阅读大量相关文献，得到确定参数的一种常用方法，就是使用L1-正则，通过实验我认为这种方法是比较有效的，因此选用了这种方式；第二个就是参数删除的比例，这个我主要是通过敏感性分析的方式，通过固定其他层，调整某一层，查看设置不同比例对精度的影响来确定，然后predifined确定剪枝的参数；还有一种是automatic的方式，比如ADC（Automated deep compression）方法，根据不同需求（如保证精度还是限制计算量），利用强化学习来学习每一层最优的sparsity ratio

其他思考：
在裁剪后加入可以撤回的这个步骤，那么在精度影响较大的时候，仍然可以恢复回来 （mask/可以扩充的剪枝方案）
自动剪枝，使用强化学习
将精度、能量消耗和数据一起作为输入，一次裁剪得到多个合适模型
https://cloud.tencent.com/developer/article/1631704 比较全面介绍+未来方向指明（2020）



NUS项目设计的挑战：
确定项目选题，也就是挖掘什么的之间关系是比较困难的，因为挖掘的内容一方面需要有心意，那么选择的可能是看似没有什么有关的项目，一方面就是如何天马星空，就可能最后面临失败的结果
因此选择的项目必须本身要具有研究的意义


#### 1. 面试官在每个环节重点关注的点
问项目：是否真实，表达能力
要把细节表达清楚，而不是面试官问啥答啥，因为对方不了解这个工作
日常多看一下工作中的难点与challenges，变为自己的

做算法：
正确的思路
corner case（易错点）的设计情况，要设想各种可能的情况（一面的面试官比较关注corner case，二面面试官和三面面试官都比较时空复杂度）
    corner case的设计：
    有重复无重复元素
    奇数还是偶数
    是否需要解决输入空格
    是否需要解决输入有溢出或者最后的结果有溢出
    是否需要担心输入包括0 或者负数
    空链表
    栈是否为空
    空/非法/正负/溢出

沟通能力：做算法时要多沟通细节，沟通自己不懂的地方
代码风格


https://gxin.yuque.com/docs/share/5eb3fa50-61f3-4b41-ad02-8d88ca29a1d1?# 别人的整理，重点！！！！



为什么想要加入这个公司


在面试得时候一定要思路清晰，在没有想清楚之前不要轻易开口





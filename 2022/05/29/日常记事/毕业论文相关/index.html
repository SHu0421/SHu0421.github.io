

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/self.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Shu">
  <meta name="keywords" content="">
  
    <meta name="description" content="毕业论文思路5-22 毕业论文计划Update看了一下之前写的论文，目前的打算：  毕业论文在之前写的算法优化相关的论文上+一些调度&#x2F;异步重要性&#x2F;缓存（字典）&#x2F;分布式训练&#x2F;pipeline 相关知识从算法+系统上构建一个针对不同瓶颈场景的深度学习训练系统算法上一些理论（使用历史值） 对系统上的优化提供了帮助系统上可从：分布式计算通讯减少，缓存设计&#x2F;减少冗余数据移动加速IO算法上优化目的减少计算时间">
<meta property="og:type" content="article">
<meta property="og:title" content="毕业论文相关">
<meta property="og:url" content="http://shu0421.github.io/2022/05/29/%E6%97%A5%E5%B8%B8%E8%AE%B0%E4%BA%8B/%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87%E7%9B%B8%E5%85%B3/index.html">
<meta property="og:site_name" content="Hello World">
<meta property="og:description" content="毕业论文思路5-22 毕业论文计划Update看了一下之前写的论文，目前的打算：  毕业论文在之前写的算法优化相关的论文上+一些调度&#x2F;异步重要性&#x2F;缓存（字典）&#x2F;分布式训练&#x2F;pipeline 相关知识从算法+系统上构建一个针对不同瓶颈场景的深度学习训练系统算法上一些理论（使用历史值） 对系统上的优化提供了帮助系统上可从：分布式计算通讯减少，缓存设计&#x2F;减少冗余数据移动加速IO算法上优化目的减少计算时间">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-05-29T08:17:07.000Z">
<meta property="article:modified_time" content="2023-11-29T02:21:21.322Z">
<meta property="article:author" content="Shu">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>毕业论文相关 - Hello World</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />

  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="//at.alicdn.com/t/c/font_4176555_qx6ctrgomb9.css">
<link rel="stylesheet" href="/css/mac.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"shu0421.github.io","root":"/","version":"1.9.5","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":"UA-294899992-1","tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"gtag":"G-MVXHSJJR3Q"},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  



  
<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Hello World" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 60vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>HU&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                <span>爱好</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/favorite/">
                    
                    <span>概述</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/favorite-reading">
                    
                    <span>阅读</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/favorite-language/">
                    
                    <span>语言</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="http://shu0421.github.io/en/">
                <i class="iconfont icon-qiehuanyuyan"></i>
                <span>English</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/bg-wenzhang-2.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="毕业论文相关"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-05-29 16:17" pubdate>
          2022年5月29日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          8.4k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          27 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">毕业论文相关</h1>
            
              <p class="note note-info">
                
                  
                    <!-- compatible with older versions-->
                    本文最后更新于：2023年11月29日 上午
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h2 id="毕业论文思路"><a href="#毕业论文思路" class="headerlink" title="毕业论文思路"></a>毕业论文思路</h2><p>5-22 毕业论文计划Update<br>看了一下之前写的论文，目前的打算：</p>
<ol>
<li>毕业论文在之前写的算法优化相关的论文上+一些调度/异步重要性/缓存（字典）/分布式训练/pipeline 相关知识<br>从算法+系统上构建一个针对不同瓶颈场景的深度学习训练系统<br>算法上一些理论（使用历史值） 对系统上的优化提供了帮助<br>系统上可从：分布式计算通讯减少，缓存设计/减少冗余数据移动加速IO<br><font color="red">算法上优化目的减少计算时间，系统上优化目的减少通讯和IO时间</font><br><font color="red"> 重要性计算(只对重要的数据进行数据增强，有论文，或者对不重要的数据进行增强后缓存)， 重要性IO（高频更新和读取重要的样本，低频读取不重要样本，异步更新重要性）， 重要性通讯（梯度异步通讯，梯度小的就不同步，梯度比较大的同步，这样同步等待时间降低） </font><br>就相当于有三轮重要性过滤，可以通过参数指定是否要使用某种方法</li>
</ol>
<p>  a. 把重要性采样算法：转为过滤和打分阶段<br>  b. 通讯：<font color="red">重要性采样算法情况下如何解决重要性采样算法带来的负载不均衡，有的重要性样本多，有的少，有的机器负载重，有的轻</font> 同构场景下也不一定要分配同样多的数据（利用调度思想解决：应该调度多少的样本到一个机器上，按照机器的剩余资源，总线占用来分配，调整batch_size lr/调度感知的通讯 or 梯度同步 or 根据topology结构来进行分组梯度同步）？进行梯度压缩通讯？进行分组异步通讯？异构集群下的通讯优化？算子融合？搜索一个最佳分配方案？超参数搜索的多job场景分布式通讯优化，减少冗余数据加载或搬运（结合Ray）？<br>  c. 数据加载时间减少，第一个batch 优先读取缓存+数据pipeline预取<br>  xxx 感知的 xxxx<br>  eg. 压缩感知的梯度同步，其实就是因为感知，所以可以pipeline，时间覆盖实现加速</p>
<p>  参考论文：并行与分布式神经网络训练中数据通路的优化<br>  可以将重要性采样算法模式关闭，但是收益于其他的优化点（负载均衡/数据预取预缓存）！</p>
<ol start="2">
<li><p>将重要性采样算法思想迁移到另外一个领域 (GNN?推荐系统？)<br>通过ali的负载分析，大量的任务要么是CPU 密集（GNN， 强化学习， CTR模型） 要么是GPU密集的，没有IO密集的。所以可以针对CPU密集场景设计重要性采样</p>
</li>
<li><p>最优的参数，样本数量，数据增强的数量或者种类应该都是随着整个训练过程中动态变化的，而不是静止最优的（pollux论文启发）</p>
</li>
</ol>
<h2 id="题目暂定"><a href="#题目暂定" class="headerlink" title="题目暂定"></a>题目暂定</h2><p>基于样本重要性与参数重要性的深度学习训练加速研究<br>基于样本重要性的深度学习加速框架（数据增强，计算，通讯，IO）<br>基于池化平台的深度学习的任务调度和资源配置研究<br>提出指标-&gt;建立模型-&gt;用模型预测-&gt;选择最佳方案</p>
<p>知网参考论文：<br>GPU集群环境下基于流水线的分布式深度学习训练优化技术研究与实现（模型并行优化）<br>分布式深度学习系统基于模型结构特性的通信优化（分布式训练通讯优化）<br>对于卷积层,根据每一层的参数规模大小设置层自适应传输率,每次进行权值参数更新时仅选择一些重要的卷积核将其梯度传输给参数服务器,其余卷积核的梯度在本地累积至下一轮参数更新</p>
<h2 id="论文模板"><a href="#论文模板" class="headerlink" title="论文模板"></a>论文模板</h2><p><a target="_blank" rel="noopener" href="https://github.com/TheNetAdmin/zjuthesis">GitHub - TheNetAdmin/zjuthesis: Zhejiang University Graduation Thesis LaTeX Template</a></p>
<h2 id="一些其他思考"><a href="#一些其他思考" class="headerlink" title="一些其他思考"></a>一些其他思考</h2><p>建立每个样本梯度对最终精度（可能在不同训练阶段不同）影响的预测模型，用这个来进行阈值选择</p>
<p>SVP没有考虑到样本重要性是动态变化，删除就再也不训练<br>AutoAssist:需要另外训练一个模型来预测，而且实际上也是随机选择<br>biggestLoss为了达到最精确，每次都要重计算每个样本，为减少IO时间带来了困难；即使提出历史值方案，也最多只能重用很短2-3epoch时间</p>
<p>最开始profile时候计算每个样本的loss以及对模型精度的贡献？如何计算？<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/400344124">抓住训练集中真正有用的样本，提升模型整体性能！ - 知乎</a> 遗忘分数删减样本  建立 <font color="red">损失/M - 模型精度关系模型</font> 这样就可能将不同模型归为一类分析</p>
<p>每个样本对模型精度的影响，好像有个数据增强的论文提到过  就是图片方格的那篇论文</p>
<ol>
<li>打印出在不同模型精度下30% 40% 70% acc 下， 不同损失，内部每层梯度的值，求每层梯度的0的比例（或者总的），如果比例大于多少（90%），就说明该损失对模型梯度的影响几乎为0;</li>
<li>或者直接引用别人如何定义损失和对模型影响两者的关系，拿来用</li>
</ol>
<p>5-29 update<br>现有的重要性采样算法只关注计算，系统无感知，因此优化有局限<br>对现有重要性采样算法提出问题（无法动态调整）-&gt; 改进算法+系统角度优化<br>存储端异步GraNd score计算+aggressive training prunning</p>
<p>重要值频繁更新-&gt; 无用数据加载  不频繁更新-&gt; subset 导致丢弃的样本无法再被计算  ===&gt; 使用异步重要性更新+multi-metric+生命周期感知调整<br>冗余数据 ===&gt; 减少数据加载，用一张图片的多个增强替代；<br>梯度重要性不同 ====&gt; 不再等待一些不重要的梯度,收到超过半数的就返回结果（适应PS）/负载感知样本划分</p>
<p>框架一个bottleneck profiler+decision maker+算法模型插件方式加入框架 可关闭可开启可单可多metric</p>
<p>弱化重要性采样算法细节，参数设定等，改为使用模型/函数/强化学习来自动确定  突出其他改进</p>
<p>5-30 update<br>BytePS重读感想：<br>将一个实现一个目标的多种方案组合起来，比如PS和Ring-AllReduce 这样不会使得CPU资源浪费，同时也不会让CPU成为瓶颈，将不同类型node之间的通讯带宽都利用起来了，CPU-GPU GPU-GPU（混合最优）<br>找到通讯的瓶颈，节点与节点间通讯bottleneck大于节点内部之间的通讯，因此将节点内部数据进行sum汇总之后再进行节点间通讯，减少通讯数据量（分组通讯）<br>将一个动作拆分为多个动作，放在不同模块上执行（模块分离，解决CPU瓶颈）</p>
<p>池化优势：我感觉CPU interfer&gt; GPU interfer可以使用池化解决，将GPU分给多任务，但是CPU分给单任务</p>
<p>data diet感想：<br>动态调整不重要样本和噪音样本的比例 判断样本噪音+重要性的准则结合起来作为multi-criterion</p>
<p>5-31<br>重要性采样算法可能会使得每个类别的数量不相等，可以打印出来看看分析本质原因<br>分析是否是模型无关的！还是数据的属性<br>多个网络选择出来的重要性分数更准确<br>自适应重要性以及噪音检测样本，通过验证集来优化<br>噪音分数指标+重要指标 一同来进行选择</p>
<p>Linear Mode Connectivity in Multitask and Continual Learning 看<br>…</p>
<h1 id="calculate-summary-statistics"><a href="#calculate-summary-statistics" class="headerlink" title="calculate summary statistics"></a>calculate summary statistics</h1><p>data_mean, data_std = mean(data), std(data)</p>
<h1 id="identify-outliers"><a href="#identify-outliers" class="headerlink" title="identify outliers"></a>identify outliers</h1><p>cut_off = data_std * 3<br>或者梯度一直保持在较高很多轮</p>
<p>, our analysis in Fig. 2 suggests a simple and powerful method to prune data for optimal performance by optimizing just two hyperparameters of a sliding window using a validation set. 利用验证集去调节参数</p>
<p>重要性作为采样概率，阈值，比例三种采样方式</p>
<ol>
<li>always, sometimes, and never samples 频率进行缓存</li>
<li>This suggests that a large portion of the dataset is composed of<br>samples that are difficult to rank</li>
</ol>
<p>评价准则（专家系统进行噪音和重要性样本的分类  Mixture of experts）+剪枝过程+静态动态 都可以进行动态配置<br>当多个任务分配到同一个GPU导致内存不够的时候，使用重要性采样？？<br>滤波器剪枝+数据剪枝 </p>
<p>6-1<br>Accelerating Deep Learning with Dynamic Data Pruning<br>虽然是动态剪枝，也就是不同轮修剪的样本是不一样的，但是这篇论文是固定间隔将所有子样本的重要性进行计算后选择一个subset进行训练<br>在进行选择的时候使用了EMA（指数移动平均）+ e-greedy(随机从不重要样本以e概率采样) /Upper-confidence bound（均值方差） 的方法，需要设置一个alpha参数。通过分数阈值来进行计算，也是一个aggressive pruning rates。<br>但是问题：随机结果有时候表现比算法好，无法解决噪音问题,而且只是介绍了criterion，但是没说是阈值还是比例采样</p>
<p>Data Fine-pruning: A Simple Way to Accelerate Neural Network Training<br>prune-epoch和reg-epoch迭代进行，而且也是具有非常多的超参数，一个window包含多个prune-epoch+reg-epoch， 而且每个window最开始的reg epoch都是不一样的; 不同点在于：删除的是loss比较大的bad data本；因为每轮prune多少样本固定，所以可以计算出来时间；而且最后的加速效果只有14%左右</p>
<p>6-2:<br>Exploring the Memorization-Generalization Continuum in Deep Learning c-score<br><a target="_blank" rel="noopener" href="https://github.com/google-research/jax-influence">GitHub - google-research/jax-influence</a> 判断样本噪音，需要使用test data, 不知道会不会影响最后的加速效果<br>如何区分hard 和noisy的样本，因为hard 样本是有助于提高精度的，但是noisy不是</p>
<p>6-3：<br>遗忘分数高的样本肯能是困难，也可能是noisy 样本，如何区分它们<br>examples with noisy labels are among the most forgotten examples, along with images with “uncommon” features<br> 现在考虑使用方差，如果是noisy 那么应该波动更大，如果是hard那么损失应该逐渐下降；之后将hard样本+ noisy（对称noisy+非对称noisy）样本 单独提取出来进行分析 (mnist+cifar10)</p>
<p> 利用数据的重要性来优化其他：增强+batch梯度通信+或者其他与数据相关决定的值！！！！</p>
<h2 id="毕业参考文献"><a href="#毕业参考文献" class="headerlink" title="毕业参考文献"></a>毕业参考文献</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/400344124">抓住训练集中真正有用的样本，提升模型整体性能！ - 知乎</a> （code NIPS 21）<br><a target="_blank" rel="noopener" href="https://github.com/mansheej/data_diet">GitHub - mansheej/data_diet</a> 上文代码</p>
<p>通过阅读后发现Data Diet是：<br>提前运行多轮，求得每轮的GradN, forget score, l2-loss 然后进行平均后将mean score保留到一个路径之后进行读取来进行数据的选择；也就是需要先验的处理，同时只有最开始的时候使用了loadsubset，之后的训练过程全部使用的subset</p>
<p><a target="_blank" rel="noopener" href="https://scholar.google.com.hk/scholar?cites=6692350500928309521&as_sdt=2005&sciodt=0,5&hl=zh-CN">Google 学术搜索</a><br>Accelerating Deep Learning with Dynamic Data Pruning 提出用强化学习/主动学习来动态查找<br>Improving Contrastive Learning on Imbalanced Data via Open-World Sampling(新领域 code NIPS21)</p>
<h2 id="之后打算"><a href="#之后打算" class="headerlink" title="之后打算"></a>之后打算</h2><p>背景+相关工作一章</p>
<p>设计一章（框架图+每个部分图表，描述每个部分怎么做）</p>
<p>实验一章（暂时将之前的实验拿过来）</p>
<p>尽量将这个事情做深一点</p>
<p>6-4<br>分析不同epoch的噪音和hard样本的损失， 方差， 或者是forget event的关系<br>猜测hard example损失逐渐减少， forget event几乎为0<br>noisy样本的损失波动很大，因为它可能会被相似的样本学习，forget event会更高<br>Learning from Noisy Labels with Complementary Loss Functions 这篇论文中有hard和noisy样本的损失的关系图</p>
<p>6-16<br>之后毕业论文打算</p>
<ol>
<li>进行主要设计部分的编写</li>
<li>添加流程图、 表</li>
<li>添加初步实验数据</li>
</ol>
<p>将重要性采样算法扩充到分布式训练可能会面临的问题<br>Furthermore, to scale out on multiple GPUs, PaGraph develops a fast GNN-computation-aware partition algorithm to avoid cross-partition access during data-parallel training and achieves better cache efficiency.</p>
<p>缓存的东西可能没用了，如何解决同时减少通讯时间</p>
<p>7.31<br>目前打算将去噪音部分加入重要性采样中<br>原来的重要性采样算法调整为低频+高频数据训练</p>
<p>算法：去噪 去冗余  重要性三个维度<br>底层：缓存，通讯压缩，负载感知调度</p>
<p>阅读论文：<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1771809">样本混进了噪声怎么办？通过Loss分布把它们揪出来！-腾讯云开发者社区-腾讯云</a></p>
<p>支持profiler度量性能瓶颈并输出cpu mem, gpu利用率报告<br>支持以插件形式（score函数单独提出来） 1）增加删除采样算法，以及2）使用单标准或者多标准， 3）分段选择样本：冗余，噪音，重要性三重过滤 （参考k8s的实现原理）<br>支持智能决策系统（RL, 启发式）</p>
<p>10-2<br>考虑去冗余+重要性数据增强<br>视频+噪音实验</p>
<p>信噪比采样：相似度分数计算一个信号，其他来计算一个噪音，重采样信号<br>加上静态和动态采样的背景工作</p>
<p>冗余减少信号，方差增加噪音， loss作为predict<br>PatchDrop - Learning When and Where to Zoom With Deep Reinforcement Learning<br>相似样本用对方替代，建立一个记录历史数据的BN</p>
<p>ScoreComputer类：</p>
<ul>
<li>initGlobalScoreComputer (global info)</li>
<li>initScoreComputer (local info)</li>
<li>startScoreComputer (collecteInfo)</li>
<li>endScoreComputer (update global info by using local info)</li>
<li>updateSamplerByScoreComputer (pass global info to sampler)</li>
</ul>
<p>Sampler</p>
<ul>
<li>use the score info to rank samples<br>主打multi-criteria<br>  redundant score+ noisy score+importance score<br>  importance score= forget event + sampling离现在的时间时长+loss/grad/E2dN score<br>  也可以自适应的加入其它criteria<br>sampling 数量<br>  model based- automatic 运用知识蒸馏的方法来训练一个轻量级模型进行重要性的预测；或者使用GRU网络根据之前时序的选择来预测之后选不选择？<br>  阈值based （缺陷：没被采样重要性无法更新）<br>  比例based acc-related 生命周期感知</li>
</ul>
<p>以插件形式非常容易扩展到其他方法，比如概率等<br>如果有缓存LFU是否有效<br>我的工作能不能应用到减少推理时延，训练一个自己设计的网络，如果我们在训练的时候使用crop image（目标检测+分类推理加速）<br>有没有去掉空间冗余加速训练的工作（PatchDrop for Efficient Training）VITmodel或许有用，classification model似乎用处不大<br><a target="_blank" rel="noopener" href="https://github.com/haitongli/knowledge-distillation-pytorch/blob/master/model/net.py">knowledge-distillation-pytorch</a> student network<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/478334890">使用 PyTorch 进行知识蒸馏 - 知乎</a></p>
<p>其他想法：能否使用细粒度的crop image来加速训练？？？</p>
<p>找文件，数据放置的位置：所有的data 会按照列表放置BS MS,然后就有一个统计文件，是在本地还是服务器？<br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/522f43ce8535">mac查找指定文件类型下包含某个字符串的文件 - 简书</a> pandas读写excel关键字查询</p>
<p>以8*8展示一下那些被选择出来的样本</p>
<ol>
<li>试试不同机器上不同batch size的实验</li>
<li>调通第一部分的算法采样率，尤其是model-based</li>
<li>频率感知的数据缓存，直接使用一个dictionary+profile LFU</li>
</ol>
<p>多准则的数据打分函数<br>基于模型能力感知的数据过滤（历史和实时模型蒸馏）<br>负载感知梯度通信</p>
<p>10.26</p>
<ul>
<li>可以扩充的地方<br>算法部分<br>API的设计<br>分布式场景中再仔细介绍一下<br>背景工作再增加几个图<br>与我优化的内容相关的技术：deep learning 训练相关，分布式通讯相关等，数据存储相关</li>
</ul>
<p>10.29：<br>实验安排：</p>
<ol>
<li>平台和训练数据集</li>
<li>整体训练性能对比</li>
<li>性能分解</li>
<li>开销</li>
<li>策略误差或者合理性分析</li>
</ol>
<p>10.30</p>
<p>多准则不像重要性采样一样，可以使用重要性值来进行预测，那么该确定样本是否应该放在缓存中，目前考虑使用一个简单的线性模型<br>cur_ratio = f(before_ratio, delata_loss/before loss)</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_36560894/article/details/107733001">PyTorch：构建线性回归模型_线性模型pytorch-CSDN博客</a> 多变量<br>LFU cache可以直接使用别人实现好的<br>自己之前实现过 LRU_Cache_Dict<br>置换策略的指定：将缓存中，当前轮已经被访问，或者当前轮根本不会被访问（self.vis ）而且重要性比当前判断样本低的样本置换出去（vis元素中小根堆，priority_queue,size,如果小根堆里面的所有元素都被删除，那么再建立一个小根堆）</p>
<p>而且字典中的value 为样本占据的百分比位置<br>LFU现在感觉就是太粗粒度了，因为大部分的样本的缓存频率是一样的，所以需要使用rank_based_cache</p>
<p>10.31</p>
<p>明天安排：将imagenet改为multi-criterion sampler的模式 使用dp(单进程多线程)进行初次实验ranked_cache lfu and lru<br>问题：缓存中被保留的始终是每轮中排序前面样本，主要是取样本的时候，还不知道样本在这一轮的损失，如何将现在样本的损失考虑进来，预测是否需要缓存？</p>
<p>将之前轮预测更重要的样本缓存下来</p>
<p>比起比较绝对分数，我们直接比较百分比位置</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/433434402">【含代码】重要强化学习算法的Pytorch实现 - 知乎</a> RL+pytorch<br><a target="_blank" rel="noopener" href="https://www.manifold.ai/exploration-vs-exploitation-in-reinforcement-learning">404: This page could not be found</a><br>Another approach is called epsilon-greedy policy, which takes action using the greedy policy with a probability of 1−𝜖 and a random action with a probability of 𝜖ϵ. This approach ensures all the action space is explored.<br><a target="_blank" rel="noopener" href="https://medium.com/@lgvaz/understanding-q-learning-the-cliff-walking-problem-80198921abbc">Understanding Q-Learning, the Cliff Walking problem | by Lucas Vazquez | Medium</a> Q-Learning的例子</p>
<p>11-1<br>VGG16 训练的时候精度下降的问题，是否需要挑战loss的计算方法<br>开销可以先写，用公式的方法</p>
<p>11-16<br>hdf5文件的生成与读取：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/19f3ca564644">图片转换成HDF5文件（加载，保存） - 简书</a><br>memcached:<a target="_blank" rel="noopener" href="https://github.com/memcached/memcached">GitHub - memcached/memcached: memcached development tree</a><br>Alluxio 其他分布式缓存上实习</p>
<p>多进程实际上就是实现了数据预取，因此每轮训练的时候因为没有进行数据的预取，可能会导致冷启动问题，为了解决冷启动，每轮训练的时候先实现缓存中的数据进行训练<br>Gist：在两次数据利用之间有长时间的gap，因此可以对数据进行压缩，之后要用的时候再解压缩， ==在cache里面对数据进行压缩解压== 问题是data没有稀疏性，如果较好的无损压缩<br>缓存里面的数据是否需要提前压缩和解压缩</p>
<p>11-17:<br>worker=0, 当使用nvme imagenet是，cache size越大，反而导致IO时间越长，实验使用nfs会不会出现这种情况<br>nvme上实验只能验证hit_ratio cache_size=0.1 不能看时间加速而且目前只有完整0.1-0.3的实验</p>
<p>同时目前在实验worker=0  ours+nfs+cache size=0.3是否比cache size=0.1快</p>
<p>11-29<br>新加一个比较对象：<br><a target="_blank" rel="noopener" href="https://proceedings.mlr.press/v162/mindermann22a.html">Prioritized Training on Points that are Learnable, Worth Learning, and not yet Learnt</a></p>
<p>12-3<br>全部从缓存中读比从nfs读数据<br>0worker大概加速6倍<br>4worker大概加速10倍</p>
<p>不管加速多少被，因为缓存只有一半，意味着至少一半的数据都要从远程文件系统中取，因此不会加速比不会超过1.5</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/poloyy/p/13519771.html">性能分析（7）- 未利用系统缓存导致 I/O 缓慢案例 - 小菠萝测试笔记 - 博客园</a> 应用使用系统缓存加速训练</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E8%AE%BA%E6%96%87/" class="print-no-link">#论文</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>毕业论文相关</div>
      <div>http://shu0421.github.io/2022/05/29/日常记事/毕业论文相关/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Shu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年5月29日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"H2RSYuSdiyJY9PtyUuEzMehk-gzGzoHsz","appKey":"VVHDe4hNQJHWFolrxe6l3FNA","path":"window.location.pathname","placeholder":"留下你的建议再离开~","avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
